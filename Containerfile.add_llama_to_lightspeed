# vim: set filetype=dockerfile
FROM localhost/local-ai-chat-lightspeed-stack:latest

USER root

ADD ./llama-stack /app-root/llama-stack

RUN python3.12 -m ensurepip

RUN cd /app-root/llama-stack && python3.12 -m pip install --editable .

RUN cd /app-root/ && python3.12 -m pip install .

USER 1001
USER root
RUN microdnf install -y patch
RUN curl -L https://github.com/meta-llama/llama-stack/commit/fd466b0459bfa7cc696ac80dba90b6e02d5869bd.patch \
  | sed '/^diff --git a\/tests\/unit\/server\/test_replace_env_vars.py b\/tests\/unit\/server\/test_replace_env_vars.py/,/^diff --git /{ /^diff --git /!d }' \
  | patch -p1 -d "$(dirname "$(dirname "$(python3 -c "import llama_stack; print(llama_stack.__file__)")")")"
USER 1001

EXPOSE 8080

