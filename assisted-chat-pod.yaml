apiVersion: v1
kind: Pod
metadata:
  name: assisted-chat-pod
spec:
  containers:
    - name: lightspeed-stack
      image: ${LIGHTSPEED_STACK_IMAGE_OVERRIDE}
      env:
        - name: GEMINI_API_KEY
          value: ${GEMINI_API_KEY}
        - name: GOOGLE_APPLICATION_CREDENTIALS
          value: /tmp/vertex-credentials.json
        - name: ASSISTED_CHAT_POSTGRES_HOST
          value: localhost
        - name: ASSISTED_CHAT_POSTGRES_PORT
          value: "5432"
        - name: ASSISTED_CHAT_POSTGRES_USER
          value: assisted-chat
        - name: ASSISTED_CHAT_POSTGRES_PASSWORD
          value: assisted-chat
        - name: ASSISTED_CHAT_POSTGRES_NAME
          value: assisted-chat
        - name: VLLM_URL
          value: ${VLLM_URL}
        - name: VLLM_API_TOKEN
          value: ${VLLM_API_TOKEN}
        - name: VLLM_TLS_VERIFY
          value: true
        - name: VLLM_REFRESH_MODELS
          value: false
      ports:
        - containerPort: 8090
          hostPort: 8090
      volumeMounts:
        - mountPath: /app-root/lightspeed-stack.yaml:Z
          name: config
          subPath: lightspeed-stack.yaml
        - mountPath: /app-root/llama_stack_client_config.yaml
          name: config
          subPath: llama_stack_client_config.yaml
        - mountPath: /tmp/systemprompt.txt
          name: config
          subPath: systemprompt.txt
        - mountPath: /tmp/vertex-credentials.json:Z
          name: config
          subPath: vertex-credentials.json
          readOnly: true
        - mountPath: /etc/tls/ca-bundle.pem
          name: config
          subPath: ca-bundle.pem
          readOnly: true
    - name: assisted-service-mcp
      image: localhost/local-ai-chat-assisted-service-mcp:latest
      env:
        - name: TRANSPORT
          value: streamable-http
      ports:
        - containerPort: 8000
          hostPort: 8000
    - name: ui
      image: localhost/local-ai-chat-ui
      env:
        - name: AIUI_CHAT_API_URL
          value: http://lightspeed-stack:8090/
        - name: AIUI_SSO_API_URL
          value: https://sso.redhat.com/auth/realms/redhat-external/protocol/openid-connect/token
        - name: AIUI_OCM_REFRESH_TOKEN
          value: ${OCM_REFRESH_TOKEN}
      ports:
        - containerPort: 8080
          hostPort: 8080
    - name: mcp-inspector
      image: localhost/local-ai-chat-inspector:latest
      env:
        - name: HOST
          value: 0.0.0.0
      ports:
        - containerPort: 6274
          hostPort: 6274
        - containerPort: 6277
          hostPort: 6277
    - name: mcphost
      image: quay.io/otuchfel/mcphost:0.9.2
      tty: true
      stdin: true
      args:
        - --config
        - /mcpconfig.json
        - --model
        - "google:gemini-2.0-flash"
        - --system-prompt
        - /systemprompt.txt
      env:
        - name: GEMINI_API_KEY
          value: ${GEMINI_API_KEY}
        - name: OCM_TOKEN
          value: ${OCM_TOKEN}
      volumeMounts:
        - mountPath: /mcpconfig.json
          name: config
          subPath: mcphost-mcp.json
        - mountPath: /systemprompt.txt
          name: config
          subPath: systemprompt.txt
    - name: postgres
      image: registry.redhat.io/rhel9/postgresql-16:latest
      env:
        - name: POSTGRESQL_USER
          value: assisted-chat
        - name: POSTGRESQL_PASSWORD
          value: assisted-chat
        - name: POSTGRESQL_DATABASE
          value: assisted-chat
      ports:
        - containerPort: 5432
          hostPort: 5432
      volumeMounts:
        - name: pgdata
          mountPath: /var/lib/pgsql/data
  volumes:
    - name: config
      hostPath:
        path: ./config
        type: Directory
    - name: pgdata
      emptyDir: {}
